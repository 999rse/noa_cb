{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Train, valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_smp_train = np.load('data/pars_smp_train.npy')\n",
    "y_smp_train = np.load('data/y_smp_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 15, 1), (1000000, 200, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pars_smp_train.shape, y_smp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size = 10000\n",
    "small_pars_smp_train = pars_smp_train[:test_data_size].copy()\n",
    "small_y_smp_train = y_smp_train[:test_data_size].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data_size != 10000000:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(small_pars_smp_train, small_y_smp_train, test_size=0.2, shuffle=False, random_state=178)\n",
    "else:\n",
    "   X_train=small_pars_smp_train\n",
    "   y_train=small_y_smp_train\n",
    "   X_valid = np.array(0)\n",
    "   y_valid = np.array(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 15, 1), (8000, 200, 3), (2000, 15, 1), (2000, 200, 3))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(small_y_smp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "if use_cuda:\n",
    "    device = 'cuda'\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class q_model(nn.Module):\n",
    "    def __init__(self, quantiles, in_shape=3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.quantiles = quantiles\n",
    "        self.num_quantiles = len(quantiles)\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = len(quantiles)\n",
    "        self.dropout = dropout\n",
    "        self.build_model()\n",
    "        self.init_weights()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Define the CNN layers\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv1d(self.in_shape, 64, kernel_size=3, padding=2, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(kernel_size=4),\n",
    "        )\n",
    "        # Define the BiLSTM layers\n",
    "        self.lstm_layers = nn.LSTM(64, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        # Define the final linear layers\n",
    "        final_layers = [\n",
    "            nn.Linear(128*2, 15) for _ in range(len(self.quantiles))  # 128 * 2 (BiLSTM) = 256\n",
    "        ]\n",
    "        \"\"\"\n",
    "        final_layers = [\n",
    "            nn.Sequential(\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 15)\n",
    "            ) for _ in range(len(self.quantiles))\n",
    "        ]\n",
    "        \"\"\"\n",
    "        self.final_layers = nn.ModuleList(final_layers)\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in chain(self.final_layers):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    \"\"\"  \n",
    "    def forward(self, x):\n",
    "        # Apply CNN layers\n",
    "        x = self.cnn_layers(x.permute(0, 2, 1))  # Adjust input shape for Conv1D\n",
    "        x = x.permute(0, 2, 1)  # Adjust back to original shape\n",
    "\n",
    "        # Apply BiLSTM layers\n",
    "        out, _ = self.lstm_layers(x)\n",
    "\n",
    "        # Use only the last time step for prediction\n",
    "        out = torch.cat([layer(out[:, -1, :]) for layer in self.final_layers], dim=1)\n",
    "        return out\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply CNN layers\n",
    "        x = self.cnn_layers(x.permute(0, 2, 1))  # Adjust input shape for Conv1D\n",
    "        x = x.permute(0, 2, 1)  # Adjust back to original shape\n",
    "\n",
    "        # Apply BiLSTM layers\n",
    "        out, _ = self.lstm_layers(x)\n",
    "\n",
    "        # Use only the last time step for prediction\n",
    "        lstm_output = out[:, -1, :]\n",
    "\n",
    "        # Initialize an empty list to store the output of each quantile head\n",
    "        quantile_outputs = []\n",
    "\n",
    "        for layer in self.final_layers:\n",
    "            quantile_output = layer(lstm_output)\n",
    "            quantile_outputs.append(quantile_output)\n",
    "\n",
    "        # Concatenate the quantile outputs along dimension 1\n",
    "        concatenated_output = torch.stack(quantile_outputs, dim=1)\n",
    "\n",
    "        return concatenated_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileLoss(nn.Module):\n",
    "    def __init__(self, quantiles):\n",
    "        super().__init__()\n",
    "        self.quantiles = quantiles\n",
    "        \n",
    "    def forward(self, preds, target):\n",
    "        assert not target.requires_grad\n",
    "        assert preds.size(0) == target.size(0)\n",
    "        losses = []\n",
    "        for i, q in enumerate(self.quantiles):\n",
    "            errors = target - preds[:, i]\n",
    "            losses.append(torch.max((q-1) * errors, q * errors).unsqueeze(1))\n",
    "        loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "class Learner:\n",
    "    def __init__(self, model, optimizer_class, loss_func, device='cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = optimizer_class(self.model.parameters())\n",
    "        self.loss_func = loss_func.to(device)\n",
    "        self.device = device\n",
    "        self.loss_history = []\n",
    "        \n",
    "    def fit(self, x, y, epochs, batch_size):\n",
    "        self.model.train()\n",
    "        for e in tqdm.tqdm(range(epochs)):\n",
    "            shuffle_idx = np.arange(x.shape[0])\n",
    "            np.random.shuffle(shuffle_idx)\n",
    "            x = x[shuffle_idx]\n",
    "            y = y[shuffle_idx]\n",
    "            epoch_losses = []\n",
    "            for idx in range(0, x.shape[0], batch_size):\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_x = torch.from_numpy(\n",
    "                    x[idx : min(idx + batch_size, x.shape[0]),:]\n",
    "                ).float().to(self.device).requires_grad_(False)\n",
    "                #print(batch_x)\n",
    "                #print(type(batch_x))\n",
    "                batch_y = torch.from_numpy(\n",
    "                    y[idx : min(idx + batch_size, y.shape[0])]\n",
    "                ).float().to(self.device).requires_grad_(False)\n",
    "                preds = self.model(batch_x)\n",
    "                loss = self.loss_func(preds, batch_y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_losses.append(loss.cpu().detach().numpy())                                \n",
    "            epoch_loss =  np.mean(epoch_losses)\n",
    "            self.loss_history.append(epoch_loss)\n",
    "            print(\"Epoch {}: {}\".format(e+1, epoch_loss))\n",
    "                \n",
    "    def predict(self, x, mc=False):\n",
    "        if mc:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        return self.model(torch.from_numpy(x).float().to(self.device).requires_grad_(False)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Learner class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "quantiles = [.1, .25, .50,.75,.90]\n",
    "model = q_model(quantiles, dropout=0.1)\n",
    "loss_func = QuantileLoss(quantiles)\n",
    "learner = Learner(model, partial(torch.optim.Adam, weight_decay=1e-6), loss_func, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 15, 1) (800, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 15)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.squeeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:12<10:17, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0.6621750593185425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:25<10:21, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 0.33339792490005493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:38<10:13, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 0.3251095712184906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:51<09:55, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 0.31483274698257446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [01:03<09:28, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 0.30406665802001953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [01:16<09:09, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 0.29234257340431213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [01:27<08:42, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 0.28545913100242615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [01:38<08:20, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 0.28166455030441284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [01:50<07:58, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 0.2770516276359558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [02:01<07:46, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 0.27500826120376587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [02:13<07:36, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 0.2692165970802307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [02:24<07:19, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 0.2624388337135315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [02:36<07:08, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 0.2550753951072693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [02:47<06:53, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 0.24950042366981506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [02:58<06:40, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 0.24630221724510193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [03:10<06:33, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 0.24128751456737518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [03:22<06:20, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 0.23685875535011292\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "epochs = 50\n",
    "learner.fit(y_train, X_train.squeeze(2), epochs, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = \"learner.class\"\n",
    "file = open(filename, 'wb') \n",
    "pickle.dump(learner, file=file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction on the meshed x-axis\n",
    "tmp = learner.predict(xx)\n",
    "y_lower, y_pred, y_upper = tmp[:, 0], tmp[:, 2], tmp[:, 4]\n",
    "\n",
    "# Plot the function, the prediction and the 90% confidence interval based on\n",
    "# the MSE\n",
    "fig = plt.figure()\n",
    "plt.plot(xx, f(xx), 'g:', label=u'$f(x) = x\\,\\sin(x)$')\n",
    "plt.plot(X, y, 'b.', markersize=10, label=u'Observations')\n",
    "plt.plot(xx, y_pred, 'r-', label=u'Prediction')\n",
    "plt.plot(xx, y_upper, 'k-')\n",
    "plt.plot(xx, y_lower, 'k-')\n",
    "plt.fill(np.concatenate([xx, xx[::-1]]),\n",
    "         np.concatenate([y_upper, y_lower[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='90% prediction interval')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.ylim(-10, 20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = learner.predict(X)\n",
    "np.mean(predictions[:, 0]), np.mean(predictions[:, 2]), np.mean(predictions[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_the_range = np.sum((y >= predictions[:, 0]) & (y <= predictions[:, 4]))\n",
    "print(\"Percentage in the range (expecting 90%):\", in_the_range / len(y) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_the_range = np.sum((y < predictions[:, 0]) | (y > predictions[:, 4]))\n",
    "print(\"Percentage out of the range (expecting 10%):\", out_of_the_range / len(y)  * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MacroEconomicModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(MacroEconomicModel, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # Используйте только последний временной шаг для предсказания\n",
    "        return out\n",
    "\n",
    "# Определение размеров входных и выходных данных\n",
    "input_size = 3  # Размерность данных о приросте ВВП, инфляции и процентной ставке\n",
    "hidden_size = 64  # Размер скрытого состояния RNN\n",
    "output_size = 15  # Размер параметров модели\n",
    "num_layers = 2  # Количество слоев LSTM     \n",
    "                                \n",
    "# Создание экземпляра модели\n",
    "model = MacroEconomicModel(input_size, hidden_size, output_size, num_layers).to(device=device)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN BiLSTM\n",
    "class CNN_BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, bidirectional, cnn_out_channels, cnn_kernel_size):\n",
    "        super(CNN_BiLSTM, self).__init__()\n",
    "        \n",
    "        # 1D Convolutional Layer\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, cnn_out_channels, kernel_size=cnn_kernel_size, stride=1),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # BiLSTM Layer\n",
    "        self.bilstm = nn.LSTM(input_size=cnn_out_channels, \n",
    "                              hidden_size=hidden_dim, \n",
    "                              num_layers=num_layers, \n",
    "                              bidirectional=bidirectional, \n",
    "                              batch_first=True)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input x: (batch_size, sequence_length, input_dim)\n",
    "        x = x.permute(0, 2, 1)  # Reshape for Conv1d: (batch_size, input_dim, sequence_length)\n",
    "        x = self.cnn(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape for BiLSTM: (batch_size, sequence_length, cnn_out_channels)\n",
    "        output, (hidden, cell) = self.bilstm(x)\n",
    "        # Take the output of the last time step\n",
    "        if self.bilstm.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1, :, :]\n",
    "        out = self.fc(hidden)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Define the model with your specific parameters\n",
    "input_dim = 3  # Input dimension\n",
    "hidden_dim = 64  # Hidden dimension for BiLSTM\n",
    "output_dim = 15  # Output dimension\n",
    "num_layers = 2  # Number of BiLSTM layers\n",
    "bidirectional = True  # Use bidirectional BiLSTM\n",
    "cnn_out_channels = 64  # Number of CNN output channels\n",
    "cnn_kernel_size = 3  # Kernel size for CNN\n",
    "\n",
    "model = CNN_BiLSTM(input_dim, hidden_dim, output_dim, num_layers, bidirectional, cnn_out_channels, cnn_kernel_size).to(device=device)\n",
    "\n",
    "# Loss & optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование данных в тензоры PyTorch\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_train = torch.Tensor(X_train)\n",
    "\n",
    "y_valid = torch.Tensor(y_valid)\n",
    "X_valid = torch.Tensor(X_valid)\n",
    "\n",
    "\n",
    "batch_size = 180\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "train_dataset = TensorDataset(y_train, X_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "valid_dataset = TensorDataset(y_valid, X_valid)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "sss = int(X_train.shape[0]/batch_size+1)\n",
    "# Обучение модели\n",
    "num_epochs = 10  # Количество эпох обучения\n",
    "history = {\n",
    "    'training_loss':[],\n",
    "    'validation_loss':[]\n",
    "}\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batch_losses = []#.to(device)\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # Обнуляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Проход вперед (forward pass)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Вычисление функции потерь\n",
    "        loss = torch.sqrt(criterion(outputs, targets.squeeze()))\n",
    "        #batch_losses.append(loss.detach().numpy())\n",
    "        batch_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #print(len(batch_losses))\n",
    "    training_loss = np.mean(batch_losses)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_val_losses = []\n",
    "        for batch_val in valid_loader:\n",
    "            inputs_val, targets_val = batch_val\n",
    "            inputs_val, targets_val = inputs_val.to(device), targets_val.to(device)\n",
    "            #print(inputs_val.shape, targets_val.shape)\n",
    "            model.eval()\n",
    "\n",
    "            # Проход вперед (forward pass)\n",
    "            outputs_val = model(inputs_val)\n",
    "\n",
    "            # Вычисление функции потерь\n",
    "            loss_val = torch.sqrt(criterion(outputs_val, targets_val.squeeze()))\n",
    "            batch_val_losses.append(loss_val)\n",
    "            #print(batch_val_losses)\n",
    "           # print(type(batch_val_losses))\n",
    "            validation_loss = torch.mean(torch.stack(batch_val_losses))\n",
    "\n",
    "\n",
    "\n",
    "    # Выводим информацию о процессе обучения\n",
    "    #print(f'Эпоха [{epoch + 1}/{num_epochs}], Потери train: {loss.item()}')\n",
    "    print(f'Эпоха [{epoch + 1}/{num_epochs}], Потери train: {training_loss.item()}, Loss valid: {validation_loss.item()}')\n",
    "    history['training_loss'].append(training_loss.item())\n",
    "    history['validation_loss'].append(validation_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history)\n",
    "from matplotlib import pyplot as plt\n",
    "#plt.plot(torch.stack(history['training_loss']).cpu())\n",
    "plt.plot(history['training_loss'])\n",
    "plt.plot(history['validation_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trained_model_CNN_BiLSTM.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_smp_test = np.load('data/y_smp_test.npy')\n",
    "y_test = torch.Tensor(y_smp_test)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader\n",
    "test_dataset = TensorDataset(y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute model on test data\n",
    "with torch.no_grad():\n",
    "    all_outputs_test = []\n",
    "    for batch in test_loader:\n",
    "        inputs_test = batch[0]\n",
    "        inputs_test = inputs_test.to(device=device)\n",
    "        model.eval()\n",
    "\n",
    "        outputs_test = model(inputs_test).unsqueeze(2)\n",
    "        all_outputs_test.append(outputs_test)\n",
    "\n",
    "    # Concat to common tensor\n",
    "    final_outputs_test = torch.cat(all_outputs_test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5  # Window size\n",
    "\n",
    "# Empty tensor for saving result\n",
    "result = torch.zeros((final_outputs_test.size(0), final_outputs_test.size(1), 6))\n",
    "\n",
    "for i in range(0, final_outputs_test.size(0), batch_size):\n",
    "    batch = final_outputs_test[i:i+batch_size]\n",
    "    \n",
    "    # Calculate mean\n",
    "    batch_mean = torch.mean(batch, dim=0).squeeze(1)\n",
    "\n",
    "    # Sort batch for calculate quantiles\n",
    "    sorted_batch, _ = torch.sort(batch, dim=0)\n",
    "    sorted_batch = sorted_batch.to(device=device)\n",
    "    quantiles = torch.quantile(sorted_batch, torch.Tensor([0.1, 0.25, 0.5, 0.75, 0.9]).to(device=device), dim=0).to(device=device)\n",
    "\n",
    "    # Save to final tensor\n",
    "    result[i:i+batch_size, :, 0] = batch_mean\n",
    "    result[i:i+batch_size, :, 1:6] = quantiles\n",
    "\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5  # Window size\n",
    "\n",
    "# Empty tensor for saving result\n",
    "result = torch.zeros((final_outputs_test.size(0), final_outputs_test.size(1), 6))\n",
    "\n",
    "for i in range(0, final_outputs_test.size(0), batch_size):\n",
    "    batch = final_outputs_test[i:i+batch_size]\n",
    "    \n",
    "    # Calculate mean\n",
    "    batch_mean = torch.mean(batch, dim=0).squeeze(1)\n",
    "\n",
    "    # Sort batch for calculate quantiles\n",
    "    sorted_batch, _ = torch.sort(batch, dim=0)\n",
    "    sorted_batch = sorted_batch.to(device=device)\n",
    "    quantiles = torch.quantile(sorted_batch, torch.Tensor([0.1, 0.25, 0.5, 0.75, 0.9]).to(device=device), dim=0)\n",
    "\n",
    "    # Save to final tensor\n",
    "    result[i:i+batch_size, :, 0] = batch_mean\n",
    "    result[i:i+batch_size, :, 1:6] = quantiles\n",
    "\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file='submission.npy', arr=result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
